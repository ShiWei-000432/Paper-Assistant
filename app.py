import streamlit as st
import os
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
import tempfile

# --- é¡µé¢é…ç½® ---
st.set_page_config(page_title="è®ºæ–‡è¾…åŠ©ç³»ç»Ÿ (AI Research Assistant)", layout="wide")

# --- ä¾§è¾¹æ ï¼šè®¾ç½®ä¸ä¸Šä¼  ---
with st.sidebar:
    st.title("âš™ï¸ ç³»ç»Ÿè®¾ç½®")
    api_key = st.text_input("è¯·è¾“å…¥ API Key (OpenAI/DeepSeek)", type="password")
    base_url = st.text_input("API Base URL (é€‰å¡«)", value="https://api.openai.com/v1", help="å¦‚æœæ˜¯DeepSeekï¼Œå¡« https://api.deepseek.com")
    
    st.divider()
    st.header("ğŸ“‚ èµ„æ–™åº“")
    uploaded_files = st.file_uploader("ä¸Šä¼ å‚è€ƒæ–‡çŒ® (PDF)", type=["pdf"], accept_multiple_files=True)
    
    process_btn = st.button("æ„å»ºçŸ¥è¯†åº“")

# --- æ ¸å¿ƒé€»è¾‘å‡½æ•° ---

def process_pdfs(files):
    """è¯»å–PDFå¹¶è¿›è¡Œåˆ‡ç‰‡å’Œå‘é‡åŒ–"""
    documents = []
    status_text = st.empty()
    progress_bar = st.progress(0)
    
    for i, file in enumerate(files):
        status_text.text(f"æ­£åœ¨è§£æ: {file.name}...")
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶å› ä¸ºPyPDFLoaderéœ€è¦è·¯å¾„
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
            tmp_file.write(file.read())
            tmp_path = tmp_file.name
        
        loader = PyPDFLoader(tmp_path)
        documents.extend(loader.load())
        os.remove(tmp_path) # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        progress_bar.progress((i + 1) / len(files))
    
    # æ–‡æœ¬åˆ‡ç‰‡ï¼šå­¦æœ¯è®ºæ–‡éœ€è¦ä¿æŒä¸Šä¸‹æ–‡ï¼Œchunk_sizeè®¾å¤§ä¸€ç‚¹
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    splits = text_splitter.split_documents(documents)
    
    return splits

def get_vector_store(splits, api_key, base_url):
    """å»ºç«‹å‘é‡ç´¢å¼•"""
    # è¿™é‡Œé»˜è®¤ä½¿ç”¨ OpenAI Embeddingsï¼Œä¹Ÿå¯ä»¥æ¢æˆ HuggingFace å…è´¹çš„
    embeddings = OpenAIEmbeddings(openai_api_key=api_key, base_url=base_url)
    vectorstore = FAISS.from_documents(splits, embeddings)
    return vectorstore

def generate_academic_response(query, vectorstore, api_key, base_url):
    """ç”Ÿæˆç¬¦åˆé¡¶åˆŠé£æ ¼çš„å›ç­”"""
    llm = ChatOpenAI(
        model_name="gpt-4o",  # æˆ–è€… deepseek-chat
        temperature=0.3, # ä½æ¸©åº¦ä¿è¯ä¸¥è°¨æ€§
        openai_api_key=api_key,
        base_url=base_url
    )
    
    # --- æ­¥éª¤ 1: æ£€ç´¢ç›¸å…³ä¿¡æ¯ ---
    retriever = vectorstore.as_retriever(search_kwargs={"k": 5}) # æ£€ç´¢æœ€ç›¸å…³çš„5ä¸ªç‰‡æ®µ
    docs = retriever.get_relevant_documents(query)
    context_text = "\n\n".join([doc.page_content for doc in docs])
    
    # --- æ­¥éª¤ 2: é¡¶åˆŠå†™æ‰‹ Agent ---
    writer_prompt = f"""
    ä½ æ˜¯ä¸€åä¸–ç•Œé¡¶å°–çš„ç ”ç©¶å‘˜ï¼Œæ­£åœ¨ä¸º Nature/Science çº§åˆ«çš„æœŸåˆŠæ’°å†™è®ºæ–‡å†…å®¹ã€‚
    
    ã€å‚è€ƒæ–‡çŒ®ç‰‡æ®µã€‘ï¼š
    {context_text}
    
    ã€ç”¨æˆ·æŒ‡ä»¤/æƒ³æ³•ã€‘ï¼š
    {query}
    
    ã€ä»»åŠ¡ã€‘ï¼š
    è¯·æ ¹æ®ç”¨æˆ·æŒ‡ä»¤ï¼Œä¸¥æ ¼åŸºäºå‚è€ƒæ–‡çŒ®ç‰‡æ®µï¼Œæ’°å†™ç›¸åº”çš„å†…å®¹ï¼ˆå¦‚å®éªŒæ–¹æ¡ˆã€å¼•è¨€æˆ–è®¨è®ºï¼‰ã€‚
    
    ã€è¦æ±‚ã€‘ï¼š
    1. é€»è¾‘ä¸¥å¯†ï¼Œå­¦æœ¯ç”¨è¯­è§„èŒƒã€‚
    2. å¿…é¡»å¼•ç”¨å‚è€ƒæ–‡çŒ®ä¸­çš„æ•°æ®æˆ–è§‚ç‚¹æ¥æ”¯æŒè®ºè¿°ã€‚
    3. ä½¿ç”¨ LaTeX æ ¼å¼ç¼–å†™æ•°å­¦å…¬å¼ã€‚
    4. ç»“æ„æ¸…æ™°ï¼Œåˆ†ç‚¹è®ºè¿°ã€‚
    5. å¦‚æœå‚è€ƒæ–‡çŒ®ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯šå®è¯´æ˜ï¼Œä¸è¦ç¼–é€ ã€‚
    
    è¯·å¼€å§‹æ’°å†™ï¼š
    """
    
    with st.spinner("âœï¸ AI ç ”ç©¶å‘˜æ­£åœ¨æ’°å†™åˆç¨¿..."):
        initial_draft = llm.invoke(writer_prompt).content
        
    return initial_draft, context_text

def reviewer_critique(draft, query, api_key, base_url):
    """å®¡ç¨¿äºº Agentï¼šæŒ‘åˆºæ¨¡å¼"""
    llm = ChatOpenAI(
        model_name="gpt-4o", 
        temperature=0.7, 
        openai_api_key=api_key,
        base_url=base_url
    )
    
    reviewer_prompt = f"""
    ä½ æ˜¯ä¸€åä»¥ä¸¥å‰è‘—ç§°çš„é¡¶çº§æœŸåˆŠå®¡ç¨¿äºº (Reviewer #2)ã€‚
    
    ã€ç”¨æˆ·åŸå§‹æ„å›¾ã€‘ï¼š{query}
    
    ã€å¾…å®¡é˜…ç¨¿ä»¶ã€‘ï¼š
    {draft}
    
    ã€ä»»åŠ¡ã€‘ï¼š
    è¯·å¯¹ä¸Šè¿°ç¨¿ä»¶è¿›è¡Œæ‰¹åˆ¤æ€§å®¡é˜…ã€‚
    1. æŒ‡å‡ºé€»è¾‘æ¼æ´ã€‚
    2. æŒ‡å‡ºè¯­è¨€æ˜¯å¦ä¸å¤Ÿå­¦æœ¯ï¼ˆToo casualï¼‰ã€‚
    3. æŒ‡å‡ºå®éªŒè®¾è®¡æ˜¯å¦ç¼ºä¹æ§åˆ¶å˜é‡ï¼ˆå¦‚æœæ˜¯å®éªŒæ–¹æ¡ˆï¼‰ã€‚
    4. ç»™å‡ºå…·ä½“çš„ä¿®æ”¹å»ºè®®ã€‚
    
    è¯·è¾“å‡ºä½ çš„å®¡é˜…æŠ¥å‘Šï¼š
    """
    
    with st.spinner("ğŸ§ å®¡ç¨¿äººæ­£åœ¨æå…¶æŒ‘å‰”åœ°æ£€æŸ¥..."):
        critique = llm.invoke(reviewer_prompt).content
        
    return critique

# --- ä¸»ç•Œé¢é€»è¾‘ ---

st.title("ğŸ“ é¡¶åˆŠè®ºæ–‡è¾…åŠ©ç³»ç»Ÿ")
st.markdown("### User Input: ä½ çš„æƒ³æ³•")

user_idea = st.text_area("åœ¨æ­¤è¾“å…¥ä½ çš„æ ¸å¿ƒIdeaã€å‡è®¾æˆ–å…·ä½“è¦æ±‚ï¼ˆæ”¯æŒçº¯æ–‡æœ¬æˆ–ä»PDFç²˜è´´ï¼‰", height=150)

if "vectorstore" not in st.session_state:
    st.session_state.vectorstore = None

# å¤„ç†ä¸Šä¼ æ–‡ä»¶
if process_btn and uploaded_files and api_key:
    if not api_key:
        st.error("è¯·å…ˆåœ¨å·¦ä¾§è¾“å…¥ API Key")
    else:
        try:
            splits = process_pdfs(uploaded_files)
            st.session_state.vectorstore = get_vector_store(splits, api_key, base_url)
            st.success(f"çŸ¥è¯†åº“æ„å»ºå®Œæˆï¼å…±å¤„ç† {len(splits)} ä¸ªæ–‡æœ¬ç‰‡æ®µã€‚")
        except Exception as e:
            st.error(f"å¤„ç†å‡ºé”™: {str(e)}")

# ç”ŸæˆæŒ‰é’®
if st.button("ğŸš€ å¼€å§‹ç”Ÿæˆè®ºæ–‡å†…å®¹"):
    if not st.session_state.vectorstore:
        st.warning("è¯·å…ˆä¸Šä¼ å‚è€ƒæ–‡çŒ®å¹¶æ„å»ºçŸ¥è¯†åº“ï¼")
    elif not user_idea:
        st.warning("è¯·è¾“å…¥ä½ çš„æƒ³æ³•ï¼")
    else:
        # 1. æ’°å†™
        draft, sources = generate_academic_response(user_idea, st.session_state.vectorstore, api_key, base_url)
        
        st.divider()
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.subheader("ğŸ“„ AI ç”Ÿæˆåˆç¨¿")
            st.markdown(draft)
            
        with col2:
            st.subheader("ğŸ“š æº¯æºä¿¡æ¯ (Context)")
            with st.expander("æŸ¥çœ‹å¼•ç”¨çš„åŸæ–‡ç‰‡æ®µ"):
                st.markdown(sources)
        
        # 2. å®¡ç¨¿
        st.divider()
        st.subheader("ğŸ§ Reviewer #2 çš„å®¡é˜…æ„è§")
        critique = reviewer_critique(draft, user_idea, api_key, base_url)
        st.info(critique)

        st.markdown("---")
        st.caption("æç¤ºï¼šä½ å¯ä»¥æ ¹æ®å®¡é˜…æ„è§ä¿®æ”¹ä½ çš„ Inputï¼Œé‡æ–°ç”Ÿæˆç›´åˆ°æ»¡æ„ã€‚")